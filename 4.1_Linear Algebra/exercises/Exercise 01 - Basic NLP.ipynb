{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./assets/poems.csv\")\n",
    "documents = data[\"Poem\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = documents.apply(lambda x: str.lower(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '/', '0', '1', '2', '5', '8', ':', ';', '?', '[', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xa0', 'è', 'é', '–', '—', '’', '“', '”', '\\u2028']\n"
     ]
    }
   ],
   "source": [
    "characters = set()\n",
    "for doc in documents:\n",
    "    words = doc.split(\" \")\n",
    "    for word in words:\n",
    "        for char in word:\n",
    "            if char not in characters:\n",
    "                characters.add(char)\n",
    "\n",
    "print(sorted(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for char in characters:\n",
    "    if char not in string.ascii_lowercase:\n",
    "        documents = documents.apply(lambda x: x.replace(char, \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'woman', 'walks', 'by', 'the', 'bench', 'im', 'sitting', 'onwith', 'her']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_docs = [doc.split() for doc in documents]\n",
    "tokenized_docs[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = set(word for doc in tokenized_docs for word in doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {word: np.random.rand(12) for word in unique_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = np.zeros((len(tokenized_docs), len(unique_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {word: i for i, word in enumerate(unique_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc_idx, doc in enumerate(tokenized_docs):\n",
    "    for word in doc:\n",
    "        word_idx = word_to_index[word]\n",
    "        dtm[doc_idx, word_idx] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    similarity = dot_product / (norm_vec1 * norm_vec2)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23588370942962128\n"
     ]
    }
   ],
   "source": [
    "similarity = cosine_similarity(dtm[0], dtm[1])\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs = dtm.shape[0]\n",
    "similarity_matrix = np.zeros((num_docs, num_docs))\n",
    "\n",
    "for i in range(num_docs):\n",
    "    for j in range(num_docs):\n",
    "        if i != j:\n",
    "            similarity_matrix[i, j] = cosine_similarity(dtm[i], dtm[j])\n",
    "        else:\n",
    "            similarity_matrix[i, j] = 1  # Document is perfectly similar to itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_indices = np.argsort(similarity_matrix[0])[::-1]\n",
    "sorted_indices[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a woman walks by the bench im sitting onwith her dog that looks part lab part buickstops and asks if i would like to dancei smile tell her of course i do we decideon a waltz that she begins to hum\n",
      "a woman was playinga man looking onand the mould of her faceand her neck and her hairwhich the rays fell uponof the two candles theresent him mentally strayingin some fancyplacewhere pain had no tracea cowled apparitioncame pushing betweenand her notes seemed to sighand the lights to burn paleas a spell\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])\n",
    "print(documents[sorted_indices[1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
